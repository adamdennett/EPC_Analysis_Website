{
  "hash": "b1916e1d8c09da65c78ed8cdb9c5af67",
  "result": {
    "markdown": "---\ntitle: \"Spatial Analysis of Building Energy Performance\"\nauthor: \"Adam Dennett\"\nformat: html\neditor: visual\n---\n\n\nThis guide will walk you through the process of downloading, geo-coding and then mapping data from The UK Government's Department for Levelling Up, Housing and Communities (DLUHC) Domestic Energy Performance Certificate (EPC) Data.\n\n**Part 1** is a guide to downloading EPC and Ordnance Survey's geo-referenced Unique Property Reference Number (UPRN) data from two APIs and linking the two datasets for mapping using R.\n\n**Part 2** will explain how to load your newly linked data into QGIS and map it, adding additional contextual data from the OS Zoomstack.\n\nIf you are not familiar with R and you want to get straight onto the mapping, download this sample dataset from [here](https://www.dropbox.com/scl/fi/e7hfs638s4f0yf2z5scux/epc_coords.csv?rlkey=klvqophka7r3o3tsb4sv2nfik&dl=0) and skip straight down to [Part 2 - Making Some Maps]\n\n# Part 1 - Getting the Data\n\n## Downloading R and RStudio\n\nTo run this tutorial you should download and install both R and RStudio onto your machine. Download and install R before you Download and Install R Studio\n\n1.  Download R from here: <https://www.r-project.org/>\n\n2.  Download RStudio from here: <https://posit.co/products/open-source/rstudio/>\n\nIf you are unfamiliar with R and RStudio, there are lots of written and video guides out there. Here is an excellent place to start: <https://education.rstudio.com/learn/beginner/>\n\nBefore going any further, make sure you are happy with writing and saving code in .r or .rmd files in a working directory, installing and librarying packages, running basic scripts.\n\n## Creating a file to store your API keys\n\nWe will be using API keys that you will need to sign up and have an account for.\n\n1.  Visit - <https://epc.opendatacommunities.org/> - and sign-up so you can access the data\n\n2.  Once signed up, sign in and wait for the email link to be sent to you to connect to the data interface\n\n3.  Scroll to the very bottom of the Domestic EPC search front page - here you should find your api key, however, click on the developer API key link below that which should take you to this page - <https://epc.opendatacommunities.org/docs/api>\n\n4.  Click on the Domestic Energy Performance Certificates API link, which should take you to this page - <https://epc.opendatacommunities.org/docs/api/domestic>\n\n5.  Open a new R Script file in RStudio - here you will save the various API key and token information you will need to access the API. Call this file keys.r and save it to your working directory\n\n6.  Back on the domestic EPC API page, it will give you information about your API username (probably your email address you signed up with) and your API key. It will also give you two authentication tokens. You need to save these in your new keys.r file.\n\n7.  In your new keys.r file, create 4 new variables and assign them the various keys and tokens you have been given, exactly as below (don't forget the quotation marks!):\n\n    -   epc_user \\<- \"your_email\\@your_domain.com\"\n\n    -   epc_api_key \\<- \"3a9f3fc....................................\"\n\n    -   epc_auth_token \\<- \"YS5kZW............................\"\n\n    -   epc_auth \\<- \"Basic YS5kZW5...........................\"\n\n8.  Save your keys.r file and close it.\n\n## Downloading EPC Data using the API\n\n-   The code below (translated into R - thanks ChatGPT - from the python examples given here: <https://epc.opendatacommunities.org/docs/api/domestic>) will download all of the data for a particular local authority of interest.\n\n-   Before running this script, make sure you have installed the three packages that are libraried at the start.\n\n-   This script downloads data for one particular local authority in the UK - Mid Sussex - code E07000228. If you want to download data for another local authority, simply change the code - <https://www.get-information-schools.service.gov.uk/Guidance/LaNameCodes>\n\n-   The API documentation is very good, and you can filter your results not just on local authority, but other spatial variables like postcode - or by any of the variables such as type of property (e.g. bungalow), size of property, EPC rating, when the certificate was lodged - or indeed any combination. Use the API documentation to edit the code below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(httr)\nlibrary(here)\nlibrary(janitor)\n\n#read in and store the variables you have just created for your API keys\nsource(\"keys.r\")\n\n# Page size (max 5000)\nquery_size <- 5000\n\n#I am using the Here package to put the CSV downloaded into a specific folder inside the current here() route - you will probably want to put yours somewhere else. Check there here package for details on how this works. \noutput_file <- here(\"output.csv\")\n\n# Base url and example query parameters\nbase_url <- 'https://epc.opendatacommunities.org/api/v1/domestic/search'\n\n#this parameter specifies a particular local authority - this is Mid-Sussex\nquery_params <- list(size = query_size, `local-authority` = 'E07000228')\n\n# Set up authentication\nheaders <- c(\n  'Accept' = 'text/csv',\n  'Authorization' = epc_auth\n)\n\n# Keep track of whether we have made at least one request for CSV headers and search-after\nfirst_request <- TRUE\n# Keep track of search-after from previous request\nsearch_after <- NULL\n\n# Open a connection to write to the output file\nfile_conn <- file(output_file, \"w\")\n\n# Loop over entries in query blocks of up to 5000 to write all the data into a file\nwhile (!is.null(search_after) || first_request) {\n  # Only set search-after if this isn't the first request\n  if (!first_request) {\n    query_params[[\"search-after\"]] <- search_after\n  }\n  \n  # Make request\n  response <- GET(url = base_url, query = query_params, add_headers(.headers=headers))\n  response_body <- content(response, as = \"text\")\n  search_after <- headers(response)$`X-Next-Search-After`\n  \n  # For CSV data, only keep the header row from the first response\n  if (!first_request && response_body != \"\") {\n    response_body <- strsplit(response_body, \"\\n\")[[1]][-1]\n  }\n  \n  # Write received data\n  writeLines(response_body, file_conn)\n  \n  first_request <- FALSE\n}\n\n# Close the file connection\nclose(file_conn)\n```\n:::\n\n\nRead the CSV file back in to your environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nepc_data <- read_csv(here(\"output.csv\")) %>% \n  clean_names()\n```\n:::\n\n\n## Get UPRN Data from the OS API\n\nThe OS Data Hub has an API which can also be used to download various Open and licence restricted datasets - <https://osdatahub.os.uk/> - using the API directly to access the data requires an amount of specialist knowledge (although there is some work in progress documentation here - <https://github.com/howaskew/OSapiR>), however colleagues at OS have also created an R package called `osdatahub` - <https://cran.r-project.org/web/packages/osdatahub/index.html> (versions are also available in Python and Javascript - <https://github.com/OrdnanceSurvey/os-api-resources>)\n\nBelow we use the `osdatahub` package to download the Open UPRN dataset from the OS servers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(osdatahub)\nlibrary(zip)\nlibrary(tidyverse)\n\n#get a list of the open datasets - uncomment to see\n#list_os_opendata()\n\n#we're interested in the OpenUPRN dataset, so get all of the relevant info into an object\nuprn = list_os_opendata('OpenUPRN')\n\n#opening up the object, can see that we want the csv, which is the first entry\nuprn$fileName[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"osopenuprn_202402_csv.zip\"\n```\n:::\n\n```{.r .cell-code}\n#now we can download it:\ndownload_os_opendata(uprn, \n                     file_name = uprn$fileName[1], \n                     output_dir = tempdir())\n\n#get the path to the zipfile you have just downloaded\nzip_file <- file.path(tempdir(), uprn$fileName[1])\n#find out what the name of the csv is within the zipfile\nzip_contents <- zip_list(zip_file)\nzip_contents$filename[3]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"osopenuprn_202402.csv\"\n```\n:::\n\n```{.r .cell-code}\ncsv_file <- zip_contents$filename[3]\n\n# Unzip the file\nunzip(zipfile = zip_file, exdir = tempdir())\n\n# Read data from the CSV file\nuprn_data <- read_csv(file.path(tempdir(), csv_file)) %>% \n  clean_names()\n```\n:::\n\n\n## Joining EPC data to UPRN data and cleaning for mapping\n\n-   First we will get some Local Authority Boundaries from the Office for National Statistics to 'trim' our EPC data with. Sometimes, due to errors in UPRN address matching, some properties are outside of the local authority we are interested in, so we need to drop these from our analysis dataset (we could try to fix, but this will take too long in this example so we'll just drop them).\n\n-   Visit the ONS Geoportal website - <https://geoportal.statistics.gov.uk/> - and navigate to a recent set of Local Authority District Boundaries - we'll go for the ones that are 'Full extent of the realm and clipped (BFC)' - at the time of writing, the latest available are from 2023, so we'll use those.\n\n-   If you click on the dataset, you should be presented with a map page - for example, like this: <https://geoportal.statistics.gov.uk/datasets/2f0b8074b6ab4af6a1ec30eb66317d12_0/explore?location=54.959083%2C-3.316939%2C6.21>\n\n-   At the bottom of the page, clicking on the \"I want to use this\" button reveals - under the 'View API Resources' button - a URL to a GeoJson file that you can download. You can copy this and paste it in the code as below\n\n-   Be warned - occasionally the URL strings to these files change and the files themselves break. If this happens, try again with another dataset - perhaps from a different year or month. Eventually you should find one that works.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(geojsonsf)\nlibrary(tmap)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThe legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\nwhich was just loaded, were retired in October 2023.\nPlease refer to R-spatial evolution reports for details, especially\nhttps://r-spatial.org/r/2023/05/15/evolution4.html.\nIt may be desirable to make the sf package available;\npackage maintainers should consider adding sf to Suggests:.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n```\n:::\n\n```{.r .cell-code}\n#download some local authority boundaries from the ONS Geoportal\nLAD_sf <- geojson_sf(\"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_May_2023_UK_BFC_V2/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in readLines(con): incomplete final line found on\n'https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_May_2023_UK_BFC_V2/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson'\n```\n:::\n\n```{.r .cell-code}\n#just plot the boundaries quickly to see if they have downloaded OK\nqtm(LAD_sf)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# filter for Mid-Sussex again\nLocal_sf <- LAD_sf %>% filter(LAD23CD == \"E07000228\")\n\nqtm(Local_sf)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\nNow we can join some coordinates to our trimmed EPC data to enable us to map it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#first have a look at the columns within the file. This should tell you that in both files, there are columns called \"uprn\" - if you haven't cleaned the column headers with janitor, they could be capitalised or something else. \nstr(epc_data)\nstr(uprn_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Join the epc_data and uprn_data files together using a left_join() function. Join on the common UPRN identifier. Then, immediately filter out all of the rows without uprns (and therefore coordinates) by piping the newly joined data into a filter function\nepc_coords <- left_join(epc_data, uprn_data, by = join_by(uprn == uprn)) %>% \n  filter(!is.na(uprn))\n\n#now write your new clean, joined data file out to a CSV\nwrite_csv(epc_coords, here(\"epc_coords.csv\"))\n```\n:::\n\n\n## Mapping Your New Data\n\n-   It is possible to map your data directly in R, however, in this exercise we are going to eventually map it in QGIS.\n\n-   We can have a quick glimpse at the data though by converting our new joined dataset into a simple features (sf) object and viewing it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLinking to GEOS 3.11.2, GDAL 3.6.2, PROJ 9.2.0; sf_use_s2() is TRUE\n```\n:::\n\n```{.r .cell-code}\n#convert the csv with coordinates in it to an sf object\nepc_sf <- st_as_sf(epc_coords, coords=c(\"x_coordinate\", \"y_coordinate\"), crs=27700)\n\n#set the CRS to british national grid\nst_crs(Local_sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinate Reference System:\n  User input: 4326 \n  wkt:\nGEOGCS[\"WGS 84\",\n      DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n          AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n      PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n      UNIT[\"degree\",0.0174532925199433,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n      AXIS[\"Latitude\",NORTH],\n      AXIS[\"Longitude\",EAST],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n```\n:::\n\n```{.r .cell-code}\nLocal_sf <- st_transform(Local_sf, 27700)\n\n#clip it as some weird places are in the dataset - data errors. \nepc_sf_clip <- epc_sf[Local_sf,]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#try and map it with tmap\nlibrary(tmap)\n\n# set to plot otherwise if you set to view, it will almost certainly crash. \ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ntmap mode set to plotting\n```\n:::\n\n```{.r .cell-code}\nqtm(epc_sf_clip)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# Part 2 - Making Some Maps\n\n## QGIS\n\n-   First, download and install QGIS from the [QGIS website](https://qgis.org/en/site/index.html) for whatever operating system you have on your computer.\n\n![](images/QGIS_Org_Frontpage.png){width=\"100%\"}\n\n-   Once you have downloaded and installed QGIS, run the program and open up a new blank project\n\n![](images/QGIS_Blank_Proj.png)\n\n-   The following information has been reproduced from [this PDF](https://www.ordnancesurvey.co.uk/documents/os-open-zoomstack-vector-tile-api.pdf) on the OS website -\n\n-   We will need the [Vector Tiles Reader](https://github.com/geometalab/Vector-Tiles-Reader-QGIS-Plugin/) plugin to allow us to get some data from OS Open Zoomstack.\n\n-   Go to *Plugins \\> Manage and Install Plugins* from the top drop down menu\n\n    ![](images/plugins.png)\n\n-   Search for Vector Tiles Reader and click the button at the bottom right to install it for use in QGIS\n\n    ![](images/vector_tiles_reader.png)\n\n-   Go back into the main project window and select *Vector \\> Vector Tiles Reader \\> Add Vector Tiles Layer...* from the top menu\n\n    ![](images/select_vector_tiles_reader.png)\n\n-   In the dialogue box, click on the Server tab and then click on 'New'\n\n    ![](images/add_layers.png)\n\n-   In the create connection dialogue box paste the URL below into the TileJsonURL box:\n\n    https://s3-eu-west-1.amazonaws.com/tiles.os.uk/v2/data/vector/open-zoomstack/config.json\n\n-   Give it a name such as 'OS Open Zoomstack' and Click Save\n\n    ![](images/create_connection.png)\n\n-   Find your new 'OS Open Zoom' Stack connection in the server tab and click Connect\n\n    ![](images/connect.png)\n\n-   In the new dialogue box that pops up click on the top layer and then holding shift use the down arrow to highlight every layer in the box. Click the base map defaults button at the bottom and then the Add button\n\n    ![](images/add_layers_vector_source.png)\n\n-   This should then add all zoomstack layers to your map\n\n    ![](images/zoomstack_layers.png)\n",
    "supporting": [
      "EPCSpatialAnalysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}