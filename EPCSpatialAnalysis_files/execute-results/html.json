{
  "hash": "5a4026af13039bdc9497d1c2f6111353",
  "result": {
    "markdown": "---\ntitle: \"Spatial Analysis of Building Energy Performance\"\nauthor: \"Adam Dennett\"\nformat: html\neditor: visual\n---\n\n\nThis guide will walk you through the process of downloading, geo-coding and then mapping data from The UK Government's Department for Levelling Up, Housing and Communities (DLUHC) Domestic Energy Performance Certificate (EPC) Data.\n\n**Part 1** is a guide to downloading EPC and Ordnance Survey's geo-referenced Unique Property Reference Number (UPRN) data from two APIs and linking the two datasets for mapping using R.\n\n**Part 2** will explain how to load your newly linked data into QGIS and map it, adding additional contextual data from the OS Zoomstack.\n\nIf you are not familiar with R and you want to get straight onto the mapping, download this sample dataset from [here](https://www.dropbox.com/scl/fi/e7hfs638s4f0yf2z5scux/epc_coords.csv?rlkey=klvqophka7r3o3tsb4sv2nfik&dl=0) and skip straight down to [Part 2 - Making Some Maps]\n\n# Part 1 - Getting the Data\n\n## Downloading R and RStudio\n\nTo run this tutorial you should download and install both R and RStudio onto your machine. Download and install R before you Download and Install R Studio\n\n1.  Download R from here: <https://www.r-project.org/>\n\n2.  Download RStudio from here: <https://posit.co/products/open-source/rstudio/>\n\nIf you are unfamiliar with R and RStudio, there are lots of written and video guides out there. Here is an excellent place to start: <https://education.rstudio.com/learn/beginner/>\n\nBefore going any further, make sure you are happy with writing and saving code in .r or .rmd files in a working directory, installing and librarying packages, running basic scripts.\n\n## Creating a file to store your API keys\n\nWe will be using API keys that you will need to sign up and have an account for.\n\n1.  Visit - <https://epc.opendatacommunities.org/> - and sign-up so you can access the data\n\n2.  Once signed up, sign in and wait for the email link to be sent to you to connect to the data interface\n\n3.  Scroll to the very bottom of the Domestic EPC search front page - here you should find your api key, however, click on the developer API key link below that which should take you to this page - <https://epc.opendatacommunities.org/docs/api>\n\n4.  Click on the Domestic Energy Performance Certificates API link, which should take you to this page - <https://epc.opendatacommunities.org/docs/api/domestic>\n\n5.  Open a new R Script file in RStudio - here you will save the various API key and token information you will need to access the API. Call this file keys.r and save it to your working directory\n\n6.  Back on the domestic EPC API page, it will give you information about your API username (probably your email address you signed up with) and your API key. It will also give you two authentication tokens. You need to save these in your new keys.r file.\n\n7.  In your new keys.r file, create 4 new variables and assign them the various keys and tokens you have been given, exactly as below (don't forget the quotation marks!):\n\n    -   epc_user \\<- \"your_email\\@your_domain.com\"\n\n    -   epc_api_key \\<- \"3a9f3fc....................................\"\n\n    -   epc_auth_token \\<- \"YS5kZW............................\"\n\n    -   epc_auth \\<- \"Basic YS5kZW5...........................\"\n\n8.  Save your keys.r file and close it.\n\n## Downloading EPC Data using the API\n\n-   The code below (translated into R - thanks ChatGPT - from the python examples given here: <https://epc.opendatacommunities.org/docs/api/domestic>) will download all of the data for a particular local authority of interest.\n\n-   Before running this script, make sure you have installed the three packages that are libraried at the start.\n\n-   This script downloads data for one particular local authority in the UK - Mid Sussex - code E07000228. If you want to download data for another local authority, simply change the code - <https://www.get-information-schools.service.gov.uk/Guidance/LaNameCodes>\n\n-   The API documentation is very good, and you can filter your results not just on local authority, but other spatial variables like postcode - or by any of the variables such as type of property (e.g. bungalow), size of property, EPC rating, when the certificate was lodged - or indeed any combination. Use the API documentation to edit the code below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(httr)\nlibrary(here)\nlibrary(janitor)\n\n#read in and store the variables you have just created for your API keys\nsource(\"keys.r\")\n\n# Page size (max 5000)\nquery_size <- 5000\n\n#I am using the Here package to put the CSV downloaded into a specific folder inside the current here() route - you will probably want to put yours somewhere else. Check there here package for details on how this works. \noutput_file <- here(\"output.csv\")\n\n# Base url and example query parameters\nbase_url <- 'https://epc.opendatacommunities.org/api/v1/domestic/search'\n\n#this parameter specifies a particular local authority - this is Mid-Sussex\nquery_params <- list(size = query_size, `local-authority` = 'E07000228')\n\n# Set up authentication\nheaders <- c(\n  'Accept' = 'text/csv',\n  'Authorization' = epc_auth\n)\n\n# Keep track of whether we have made at least one request for CSV headers and search-after\nfirst_request <- TRUE\n# Keep track of search-after from previous request\nsearch_after <- NULL\n\n# Open a connection to write to the output file\nfile_conn <- file(output_file, \"w\")\n\n# Loop over entries in query blocks of up to 5000 to write all the data into a file\nwhile (!is.null(search_after) || first_request) {\n  # Only set search-after if this isn't the first request\n  if (!first_request) {\n    query_params[[\"search-after\"]] <- search_after\n  }\n  \n  # Make request\n  response <- GET(url = base_url, query = query_params, add_headers(.headers=headers))\n  response_body <- content(response, as = \"text\")\n  search_after <- headers(response)$`X-Next-Search-After`\n  \n  # For CSV data, only keep the header row from the first response\n  if (!first_request && response_body != \"\") {\n    response_body <- strsplit(response_body, \"\\n\")[[1]][-1]\n  }\n  \n  # Write received data\n  writeLines(response_body, file_conn)\n  \n  first_request <- FALSE\n}\n\n# Close the file connection\nclose(file_conn)\n```\n:::\n\n\nRead the CSV file back in to your environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nepc_data <- read_csv(here(\"output.csv\")) %>% \n  clean_names()\n```\n:::\n\n\n## Get UPRN Data from the OS API\n\nThe OS Data Hub has an API which can also be used to download various Open and licence restricted datasets - <https://osdatahub.os.uk/> - using the API directly to access the data requires an amount of specialist knowledge (although there is some work in progress documentation here - <https://github.com/howaskew/OSapiR>), however colleagues at OS have also created an R package called `osdatahub` - <https://cran.r-project.org/web/packages/osdatahub/index.html> (versions are also available in Python and Javascript - <https://github.com/OrdnanceSurvey/os-api-resources>)\n\nBelow we use the `osdatahub` package to download the Open UPRN dataset from the OS servers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(osdatahub)\nlibrary(zip)\nlibrary(tidyverse)\n\n#get a list of the open datasets - uncomment to see\n#list_os_opendata()\n\n#we're interested in the OpenUPRN dataset, so get all of the relevant info into an object\nuprn = list_os_opendata('OpenUPRN')\n\n#opening up the object, can see that we want the csv, which is the first entry\nuprn$fileName[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"osopenuprn_202402_csv.zip\"\n```\n:::\n\n```{.r .cell-code}\n#now we can download it:\ndownload_os_opendata(uprn, \n                     file_name = uprn$fileName[1], \n                     output_dir = tempdir())\n\n#get the path to the zipfile you have just downloaded\nzip_file <- file.path(tempdir(), uprn$fileName[1])\n#find out what the name of the csv is within the zipfile\nzip_contents <- zip_list(zip_file)\nzip_contents$filename[3]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"osopenuprn_202402.csv\"\n```\n:::\n\n```{.r .cell-code}\ncsv_file <- zip_contents$filename[3]\n\n# Unzip the file\nunzip(zipfile = zip_file, exdir = tempdir())\n\n# Read data from the CSV file\nuprn_data <- read_csv(file.path(tempdir(), csv_file)) %>% \n  clean_names()\n```\n:::\n\n\n## Joining EPC data to UPRN data and cleaning for mapping\n\n-   First we will get some Local Authority Boundaries from the Office for National Statistics to 'trim' our EPC data with. Sometimes, due to errors in UPRN address matching, some properties are outside of the local authority we are interested in, so we need to drop these from our analysis dataset (we could try to fix, but this will take too long in this example so we'll just drop them).\n\n-   Visit the ONS Geoportal website - <https://geoportal.statistics.gov.uk/> - and navigate to a recent set of Local Authority District Boundaries - we'll go for the ones that are 'Full extent of the realm and clipped (BFC)' - at the time of writing, the latest available are from 2023, so we'll use those.\n\n-   If you click on the dataset, you should be presented with a map page - for example, like this: <https://geoportal.statistics.gov.uk/datasets/2f0b8074b6ab4af6a1ec30eb66317d12_0/explore?location=54.959083%2C-3.316939%2C6.21>\n\n-   At the bottom of the page, clicking on the \"I want to use this\" button reveals - under the 'View API Resources' button - a URL to a GeoJson file that you can download. You can copy this and paste it in the code as below\n\n-   Be warned - occasionally the URL strings to these files change and the files themselves break. If this happens, try again with another dataset - perhaps from a different year or month. Eventually you should find one that works.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(geojsonsf)\nlibrary(tmap)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThe legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\nwhich was just loaded, were retired in October 2023.\nPlease refer to R-spatial evolution reports for details, especially\nhttps://r-spatial.org/r/2023/05/15/evolution4.html.\nIt may be desirable to make the sf package available;\npackage maintainers should consider adding sf to Suggests:.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n```\n:::\n\n```{.r .cell-code}\n#download some local authority boundaries from the ONS Geoportal\nLAD_sf <- geojson_sf(\"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_May_2023_UK_BFC_V2/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in readLines(con): incomplete final line found on\n'https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_May_2023_UK_BFC_V2/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson'\n```\n:::\n\n```{.r .cell-code}\n#just plot the boundaries quickly to see if they have downloaded OK\nqtm(LAD_sf)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# filter for Mid-Sussex again\nLocal_sf <- LAD_sf %>% filter(LAD23CD == \"E07000228\")\n\nqtm(Local_sf)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\nNow we can join some coordinates to our trimmed EPC data to enable us to map it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#first have a look at the columns within the file. This should tell you that in both files, there are columns called \"uprn\" - if you haven't cleaned the column headers with janitor, they could be capitalised or something else. \nstr(epc_data)\nstr(uprn_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Join the epc_data and uprn_data files together using a left_join() function. Join on the common UPRN identifier. Then, immediately filter out all of the rows without uprns (and therefore coordinates) by piping the newly joined data into a filter function\nepc_coords <- left_join(epc_data, uprn_data, by = join_by(uprn == uprn)) %>% \n  filter(!is.na(uprn))\n\n#now write your new clean, joined data file out to a CSV\nwrite_csv(epc_coords, here(\"epc_coords.csv\"))\n```\n:::\n\n\n## Mapping Your New Data\n\n-   It is possible to map your data directly in R, however, in this exercise we are going to eventually map it in QGIS.\n\n-   We can have a quick glimpse at the data though by converting our new joined dataset into a simple features (sf) object and viewing it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLinking to GEOS 3.11.2, GDAL 3.6.2, PROJ 9.2.0; sf_use_s2() is TRUE\n```\n:::\n\n```{.r .cell-code}\n#convert the csv with coordinates in it to an sf object\nepc_sf <- st_as_sf(epc_coords, coords=c(\"x_coordinate\", \"y_coordinate\"), crs=27700)\n\n#set the CRS to british national grid\nst_crs(Local_sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinate Reference System:\n  User input: 4326 \n  wkt:\nGEOGCS[\"WGS 84\",\n      DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n          AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n      PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n      UNIT[\"degree\",0.0174532925199433,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n      AXIS[\"Latitude\",NORTH],\n      AXIS[\"Longitude\",EAST],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n```\n:::\n\n```{.r .cell-code}\nLocal_sf <- st_transform(Local_sf, 27700)\n\n#clip it as some weird places are in the dataset - data errors. \nepc_sf_clip <- epc_sf[Local_sf,]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#try and map it with tmap\nlibrary(tmap)\n\n# set to plot otherwise if you set to view, it will almost certainly crash. \ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ntmap mode set to plotting\n```\n:::\n\n```{.r .cell-code}\nqtm(epc_sf_clip)\n```\n\n::: {.cell-output-display}\n![](EPCSpatialAnalysis_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# Part 2 - Making Some Maps\n\n## QGIS\n\n-   First, download and install QGIS from the [QGIS website](https://qgis.org/en/site/index.html) for whatever operating system you have on your computer.\n\n![](images/QGIS_Org_Frontpage.png){width=\"100%\"}\n\n-   Once you have downloaded and installed QGIS, run the program and open up a new blank project\n\n![](images/QGIS_Blank_Proj.png)\n\n### OS Open Zoomstack - Connecting for Basemap Data\n\n-   The following information has been reproduced from [this PDF](https://www.ordnancesurvey.co.uk/documents/os-open-zoomstack-vector-tile-api.pdf) on the OS website -\n\n-   We will need the [Vector Tiles Reader](https://github.com/geometalab/Vector-Tiles-Reader-QGIS-Plugin/) plugin to allow us to get some data from OS Open Zoomstack.\n\n-   Go to *Plugins \\> Manage and Install Plugins* from the top drop down menu\n\n    ![](images/plugins.png)\n\n-   Search for Vector Tiles Reader and click the button at the bottom right to install it for use in QGIS\n\n    ![](images/vector_tiles_reader.png)\n\n-   Go back into the main project window and select *Vector \\> Vector Tiles Reader \\> Add Vector Tiles Layer...* from the top menu\n\n    ![](images/select_vector_tiles_reader.png)\n\n-   In the dialogue box, click on the Server tab and then click on 'New'\n\n    ![](images/add_layers.png)\n\n-   In the create connection dialogue box paste the URL below into the TileJsonURL box:\n\n    ***https://s3-eu-west-1.amazonaws.com/tiles.os.uk/v2/data/vector/open-zoomstack/config.json***\n\n-   Give it a name such as 'OS Open Zoomstack' and Click Save\n\n    ![](images/create_connection.png)\n\n-   Find your new 'OS Open Zoom' Stack connection in the server tab and click Connect\n\n    ![](images/connect.png)\n\n-   In the new dialogue box that pops up click on the top layer and then holding shift use the down arrow to highlight every layer in the box. Click the base map defaults button at the bottom and then the Add button\n\n    ![](images/add_layers_vector_source.png)\n\n-   This should then add all zoomstack layers to your map\n\n    ![](images/zoomstack_layers.png)\n\n### Importing your EPC Data and Creating a New Points Dataset\n\n-   Whether you ran the scripts in Part 1 of this guide or downloaded my pre-made dataset, you should have a file called ***epc_coords.csv*** stored somewhere on your computer.\n\n-   We need to import this file using the QGIS Data Source Manager - whatever you do, don't just try and drag this .csv file straight into the layers window in QGIS. It will let you do it, but it will import every column in your table as text data - which will cause us all kinds of problems later on.\n\n-   Click on the data source manager icon - ![](images/data_source_manager.png) or find it under Layers \\> Data Source Manager from the top dropdown menu.\n\n![](images/data_source_manager_window.png)\n\n-   Something like the box above should appear. In the left-hand icon menu, select '*Delimited Text*' as we will be loading a .csv (comma separated/delimited variables) text file.\n\n-   At the very top of the window, click the three dots (...) in the top right hand corner and navigate to wherever your ***epc_coords.csv*** file is stored.\n\n-   There are a few little bits of housekeeping you now need to take care of **before** clicking the *Add* button at the bottom, or your data will not load in correctly.\n\n    -   Firstly we are going to plot the houses in the EPC dataset as Points on a map. In order to plot these points, you need to tell QGIS, firstly that you want it to plot points, and secondly, which columns to get your points from.\n\n    -   Under 'Geometry Definition', make sure that the radar button for 'Point Coordinates' is selected. Then, you need to choose the correct columns in your data for the x and y coordinates. You actually have two sets of x and y coordinates you could use. The columns labelled x_coordinate and y_coordinate are self-explanatory and contain *Projected* British National Grid Eastings (x) and Northings (y) - if you use these columns as in the example above, make sure your Geometry CRS is set to \"EPSG: 27700 - OSGB36 / British National Grid\"\n\n    -   You also have latitude (y) and longitude (x) that you could use to plot your points, but these are in the global *Geographic* coordinate system known as WGS84 (EPSG 4326) so if you select these columns, you will need to change the Geometry CRS accordingly.\n\n    -   The final piece of housekeeping that is required is to make sure that all of the columns you import from the CSV are imported as text and numbers (either whole integers or decimal points) correctly.\n\n    -   To do this, at the very bottom of the window, you will see an example of the data that will be imported, with the column header (which hopefully will have been automatically detected by QGIS - if not, you may need to edit under the Record and Fields options). Below the column header is the type of data that QGIS thinks your data is - probably either Text (String), Integer (32 bit) or Decimal (double) - you may also have some Date values too.\n\n    -   Move the slider along and check that all of the data types match the data below - QGIS may have guessed some numbers are text, for example - this is probably where missing values have been stored as \"NA\". Where this happens, simply click the small arrow next to the data type and change it to the correct type - usually Integer or Decimal. Do this for all incorrect columns (there will be a few). Anything that is a count or a proportion should be a number. If you're not sure, you can always open your CSV in excel first to check - but never save it afterwards as excel will cause you even more problems.\n\n    -   Once you have corrected all of the fields that will be read in, click the \"Add\" button in the bottom right of the window. At this point, you might get a window that pops up explaining that QGIS is going to try and convert your data to another coordinate system. This is fine, just leave it on the default and click \"OK\".\n\n    -   Close the data source manager and you should see a large number of points plotted in your main window.\n\n## Creating Your Map\n\n### Basic Plotting of EPCs and Contextual Information\n\n-   We can now begin to build our map of domestic energy performance for any town or village in our study area - you could look at the whole study area too, but there are a lot of data points, so zooming in might be best at this stage. \n\n-   In the Layers panel on the left of QGIS, your epc_coords layer should be on the top, if it is not, you can simply left-click and drag it to the top. \n\n-   Right Clicking on your layer will allow you to zoom to your layer if you can't find it on your map. \n\n-   At this point you can add some contextual information from Zoomstack. You may already have all layers showing, so un-tick most of them and perhaps just leave information such as buildings, railways and roads. Your resulting map may look a little like the one below:\n\n![](images/epc_and_zoomstack1.png)\n### \n\n",
    "supporting": [
      "EPCSpatialAnalysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}